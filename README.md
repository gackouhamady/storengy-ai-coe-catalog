# ğŸš€ Objectif du projet
Prototyper un **â€œAI Use-Case Catalogâ€** pour Storengy CoE Data & IA, couvrant :

- **Identification & cadrage** de deux cas dâ€™usage Ã  fort enjeu (transition Ã©nergÃ©tique & RSE)  
- **ModÃ©lisation Data Science** :
  1. **Forecasting & dÃ©tection dâ€™anomalies** sur sÃ©ries temporelles de capteurs (pression, tempÃ©rature)  
  2. **Assistant GÃ©nÃ©ratif** (GenAI) pour la documentation technique et les procÃ©dures internes  
- **DÃ©monstrateur dâ€™adoption** : interface locale simple (Streamlit) pour alimenter, visualiser et interagir  
- **Pipeline MLOps lÃ©ger** (MLflow, FastAPI), tests unitaires, documentation et mode Â« prÃªt Dataiku/GCP Â»

---

## ğŸ“… Planning dÃ©taillÃ© sur 5 jours ouvrÃ©s (+ 2 jours de buffer)

| Jour   | TÃ¢ches clÃ©s                                                                                                                                                                                                                     |
|:------:|:--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| Jour 1 | - **Init repo & env** : `git init` + venv Python, `requirements.txt` (pandas, numpy, scikit-learn, prophet, torch, transformers, streamlit, mlflow, fastapi, uvicornâ€¦) et `.gitignore`<br> - **Datasets synthÃ©tiques** :  <br>  â€¢ CSV capteurs (1 000 enregistrements)  <br>  â€¢ Corpus â€œprocÃ©duresâ€ (10 docs Markdown) |
| Jour 2 | - **Ingestion & EDA** (`src/ingestion.py`) : lecture CSV capteurs & Markdown, nettoyage, normalisation, premiÃ¨res visualisations (matplotlib/Streamlit)                                                                       |
| Jour 3 | - **Forecasting & dÃ©tection dâ€™anomalies** (`src/time_series_model.py`) :  <br>  â€¢ Prophet ou LSTM univariÃ© pour prÃ©voir la pression<br>  â€¢ Isolation Forest pour repÃ©rer anomalies<br>  â€¢ KPIs : MAE, recall anomalies    |
| Jour 4 | - **Assistant GÃ©nÃ©ratif** (`src/genai_model.py`) :  <br>  â€¢ Fine-tuning local de DistilGPT-2 sur le corpus Markdown<br>  â€¢ Endpoints Q&A (FastAPI)<br>  â€¢ Ã‰valuation qualitative (prompt tests)                               |
| Jour 5 | - **Pipeline & dÃ©monstrateur** (`src/app.py`) :  <br>  â€¢ Orchestration ingestion â†’ prÃ©diction capteurs â†’ GenAI Q&A â†’ dashboard Streamlit<br>  â€¢ ExpÃ©riences MLflow (params & metrics)<br>  â€¢ Monitor sanity checks (> seuils) |
| Jour 6 | - **Documentation & tests** :  <br>  â€¢ `README.md` (installation, usage, migration Dataiku/GCP)  <br>  â€¢ Diagramme du flow dans `docs/`  <br>  â€¢ Tests pytest pour chaque module                                            |
| Jour 7 | - **Packaging & livraison** :  <br>  â€¢ GÃ©nÃ©rer `requirements.txt` final  <br>  â€¢ Dockerfile (`python:3.10`) pour app FastAPI/Streamlit  <br>  â€¢ Commit, push sur GitHub + plan de dÃ©ploiement Cloud Run/Vertex AI                  |

---

## âš™ï¸ Structure Git finale

```bash
storengy-ai-coe-catalog/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                   # CSV capteurs & corpus Markdown
â”‚   â””â”€â”€ processed/             # after cleaning
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ flow_diagram.png       # pipeline visuel
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ ingestion.py           # ingestion & EDA
â”‚   â”œâ”€â”€ time_series_model.py   # forecasting & anomaly detection
â”‚   â”œâ”€â”€ genai_model.py         # fine-tuning & Q&A GenAI
â”‚   â”œâ”€â”€ app.py                 # Streamlit + orchestration FastAPI
â”‚   â””â”€â”€ mlflow_setup.py        # config MLflow
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_ingestion.py
â”‚   â”œâ”€â”€ test_time_series.py
â”‚   â”œâ”€â”€ test_genai.py
â”‚   â””â”€â”€ test_app.py
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â””â”€â”€ .gitignore
